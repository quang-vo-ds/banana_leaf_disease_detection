{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM4V3dP40/ElI+kanfcSfLX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/quang-vo-ds/banana_leaf_disease_detection/blob/main/banana_leaf_disease_train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initial Setup"
      ],
      "metadata": {
        "id": "-jopmhMLLl9L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install pydicom\n",
        "!pip -q install timm\n",
        "!pip -q install catalyst"
      ],
      "metadata": {
        "id": "s9v_bd92Lusm"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from glob import glob\n",
        "from sklearn.model_selection import GroupKFold, StratifiedKFold\n",
        "import cv2\n",
        "from skimage import io\n",
        "import torch\n",
        "from torch import nn\n",
        "import os\n",
        "from datetime import datetime\n",
        "import time\n",
        "import random\n",
        "import cv2\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "from torch.utils.data.sampler import SequentialSampler, RandomSampler\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "from torch.nn.modules.loss import _WeightedLoss\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import sklearn\n",
        "import warnings\n",
        "import joblib\n",
        "from sklearn.metrics import roc_auc_score, log_loss\n",
        "from sklearn import metrics\n",
        "import warnings\n",
        "import cv2\n",
        "import pydicom\n",
        "import timm\n",
        "#from efficientnet_pytorch import EfficientNet\n",
        "from scipy.ndimage import zoom"
      ],
      "metadata": {
        "id": "mKJsbgMzLfaH"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/MyDrive/Vin_ML_Course/Final_Project\n",
        "root_dir = os.getcwd()\n",
        "train_dir = os.path.join(root_dir, \"data/train_test/train\")\n",
        "save_model_dir = os.path.join(root_dir, \"output/checkpoints\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fnP3KOruMLVw",
        "outputId": "3604889e-3258-46f6-8a94-03f67d355500"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/MyDrive/Vin_ML_Course/Final_Project\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CFG = {\n",
        "    'fold_num': 5,\n",
        "    'seed': 719,\n",
        "    'model_arch': 'tf_efficientnet_b4_ns',\n",
        "    'img_size': 512,\n",
        "    'train_all': False,\n",
        "    'epochs': 10,\n",
        "    'train_bs': 16,\n",
        "    'valid_bs': 32,\n",
        "    'T_0': 10,\n",
        "    'lr': 1e-4,\n",
        "    'min_lr': 1e-6,\n",
        "    'weight_decay':1e-6,\n",
        "    'num_workers': 4,\n",
        "    'accum_iter': 2, # suppoprt to do batch accumulation for backprop with effectively larger batch size\n",
        "    'verbose_step': 1,\n",
        "    'device': 'cuda:0'\n",
        "}"
      ],
      "metadata": {
        "id": "XcqoTXgRLkdk"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv(os.path.join(train_dir, \"train.csv\"))\n",
        "train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "gz9uM57NMH1k",
        "outputId": "7081dccf-e4fa-4db1-848d-a64c5b04b9b4"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                       id  label      label_name\n",
              "0          cordana23.jpeg      3         cordana\n",
              "1          healthy27.jpeg      0         healthy\n",
              "2  pestalotiopsis172.jpeg      1  pestalotiopsis\n",
              "3          cordana18.jpeg      3         cordana\n",
              "4         sigatoka11.jpeg      2        sigatoka"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1a8b4a78-d516-476c-a98f-d9b500562753\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "      <th>label_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>cordana23.jpeg</td>\n",
              "      <td>3</td>\n",
              "      <td>cordana</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>healthy27.jpeg</td>\n",
              "      <td>0</td>\n",
              "      <td>healthy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>pestalotiopsis172.jpeg</td>\n",
              "      <td>1</td>\n",
              "      <td>pestalotiopsis</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>cordana18.jpeg</td>\n",
              "      <td>3</td>\n",
              "      <td>cordana</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>sigatoka11.jpeg</td>\n",
              "      <td>2</td>\n",
              "      <td>sigatoka</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1a8b4a78-d516-476c-a98f-d9b500562753')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1a8b4a78-d516-476c-a98f-d9b500562753 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1a8b4a78-d516-476c-a98f-d9b500562753');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-71fd62c2-9352-4c39-96a5-800398f82965\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-71fd62c2-9352-4c39-96a5-800398f82965')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const charts = await google.colab.kernel.invokeFunction(\n",
              "          'suggestCharts', [key], {});\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-71fd62c2-9352-4c39-96a5-800398f82965 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Utils"
      ],
      "metadata": {
        "id": "BU6d5_iQMv3r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "def get_img(path):\n",
        "    im_bgr = cv2.imread(path)\n",
        "    im_rgb = im_bgr[:, :, ::-1]\n",
        "    return im_rgb"
      ],
      "metadata": {
        "id": "BLcXOgSvMxBw"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset"
      ],
      "metadata": {
        "id": "TXU0EMOuM0Ja"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BananaDataset(Dataset):\n",
        "    def __init__(self, df,\n",
        "                 data_root=train_dir,\n",
        "                 transforms=None,\n",
        "                 output_label=True,\n",
        "                 one_hot_label=False,\n",
        "                ):\n",
        "\n",
        "        super().__init__()\n",
        "        self.df = df.copy()\n",
        "        self.data_root = data_root\n",
        "        self.transforms = transforms\n",
        "        self.output_label = output_label\n",
        "        self.one_hot_label = one_hot_label\n",
        "\n",
        "        if output_label == True:\n",
        "            self.labels = self.df['label'].values\n",
        "            if one_hot_label is True:\n",
        "                self.labels = np.eye(self.df['label'].max()+1)[self.labels]\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.df.shape[0]\n",
        "\n",
        "    def __getitem__(self, index: int):\n",
        "\n",
        "        # get labels\n",
        "        if self.output_label:\n",
        "            target = self.labels[index]\n",
        "\n",
        "        img_dir = os.path.join(self.data_root, self.df.iloc[index]['id'])\n",
        "        img  = get_img(img_dir)\n",
        "\n",
        "        if self.transforms:\n",
        "            img = self.transforms(image=img)['image']\n",
        "\n",
        "        if self.output_label == True:\n",
        "            return img, target\n",
        "        else:\n",
        "            return img"
      ],
      "metadata": {
        "id": "IUwate-fM3jo"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Image Augmentation"
      ],
      "metadata": {
        "id": "_1GKzVnyRUfn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from albumentations import (\n",
        "    HorizontalFlip, VerticalFlip, IAAPerspective, ShiftScaleRotate, CLAHE, RandomRotate90,\n",
        "    Transpose, ShiftScaleRotate, Blur, OpticalDistortion, GridDistortion, HueSaturationValue,\n",
        "    IAAAdditiveGaussianNoise, GaussNoise, MotionBlur, MedianBlur, IAAPiecewiseAffine, RandomResizedCrop,\n",
        "    IAASharpen, IAAEmboss, RandomBrightnessContrast, Flip, OneOf, Compose, Normalize, Cutout, CoarseDropout, ShiftScaleRotate, CenterCrop, Resize\n",
        ")\n",
        "\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "\n",
        "def get_train_transforms():\n",
        "    return Compose([\n",
        "        RandomResizedCrop(CFG['img_size'], CFG['img_size']),\n",
        "        Transpose(p=0.5),\n",
        "        HorizontalFlip(p=0.5),\n",
        "        VerticalFlip(p=0.5),\n",
        "        ShiftScaleRotate(p=0.5),\n",
        "        HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2, p=0.5),\n",
        "        RandomBrightnessContrast(brightness_limit=(-0.1,0.1), contrast_limit=(-0.1, 0.1), p=0.5),\n",
        "        Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n",
        "        CoarseDropout(p=0.5),\n",
        "        Cutout(p=0.5),\n",
        "        ToTensorV2(p=1.0),\n",
        "        ], p=1.)\n",
        "\n",
        "\n",
        "def get_valid_transforms():\n",
        "    return Compose([\n",
        "        Resize(CFG['img_size'], CFG['img_size']),\n",
        "        Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n",
        "        ToTensorV2(p=1.0),\n",
        "        ], p=1.)"
      ],
      "metadata": {
        "id": "sdXgdHk8QINA"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model"
      ],
      "metadata": {
        "id": "pErQoofORitO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyImgClassifier(nn.Module):\n",
        "    def __init__(self, model_arch, n_class, pretrained=False):\n",
        "        super().__init__()\n",
        "        self.model = timm.create_model(model_arch, pretrained=pretrained)\n",
        "        n_features = self.model.classifier.in_features\n",
        "        self.model.classifier = nn.Linear(n_features, n_class)\n",
        "        '''\n",
        "        self.model.classifier = nn.Sequential(\n",
        "            nn.Dropout(0.3),\n",
        "            #nn.Linear(n_features, hidden_size,bias=True), nn.ELU(),\n",
        "            nn.Linear(n_features, n_class, bias=True)\n",
        "        )\n",
        "        '''\n",
        "    def forward(self, x):\n",
        "        x = self.model(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "E9Q_NTX5RtZQ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training API"
      ],
      "metadata": {
        "id": "UCkmZiioU-Oz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_dataloader(df, trn_idx, val_idx, train_all=CFG['train_all']):\n",
        "\n",
        "    from catalyst.data.sampler import BalanceClassSampler\n",
        "\n",
        "    train_ = df.loc[trn_idx,:].reset_index(drop=True)\n",
        "    valid_ = df.loc[val_idx,:].reset_index(drop=True)\n",
        "\n",
        "    train_ds = BananaDataset(train_, data_root=train_dir, transforms=get_train_transforms(), output_label=True, one_hot_label=False)\n",
        "    valid_ds = BananaDataset(valid_, data_root=train_dir, transforms=get_valid_transforms(), output_label=True)\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        train_ds,\n",
        "        batch_size=CFG['train_bs'],\n",
        "        pin_memory=False,\n",
        "        drop_last=False,\n",
        "        shuffle=True,\n",
        "        num_workers=CFG['num_workers'],\n",
        "        #sampler=BalanceClassSampler(labels=train_['label'].values, mode=\"downsampling\")\n",
        "    )\n",
        "    val_loader = torch.utils.data.DataLoader(\n",
        "        valid_ds,\n",
        "        batch_size=CFG['valid_bs'],\n",
        "        num_workers=CFG['num_workers'],\n",
        "        shuffle=False,\n",
        "        pin_memory=False,\n",
        "    )\n",
        "    return train_loader, val_loader\n",
        "\n",
        "def train_one_epoch(epoch, model, loss_fn, optimizer, train_loader, device, scaler, scheduler=None, schd_batch_update=False):\n",
        "    model.train()\n",
        "\n",
        "    t = time.time()\n",
        "    running_loss = None\n",
        "\n",
        "    pbar = tqdm(enumerate(train_loader), total=len(train_loader))\n",
        "    for step, (imgs, image_labels) in pbar:\n",
        "        imgs = imgs.to(device).float()\n",
        "        image_labels = image_labels.to(device).long()\n",
        "\n",
        "        with autocast():\n",
        "            image_preds = model(imgs)\n",
        "\n",
        "            loss = loss_fn(image_preds, image_labels)\n",
        "\n",
        "            scaler.scale(loss).backward()\n",
        "\n",
        "            if running_loss is None:\n",
        "                running_loss = loss.item()\n",
        "            else:\n",
        "                running_loss = running_loss * .99 + loss.item() * .01\n",
        "\n",
        "            if ((step + 1) %  CFG['accum_iter'] == 0) or ((step + 1) == len(train_loader)):\n",
        "                # may unscale_ here if desired (e.g., to allow clipping unscaled gradients)\n",
        "\n",
        "                scaler.step(optimizer)\n",
        "                scaler.update()\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                if scheduler is not None and schd_batch_update:\n",
        "                    scheduler.step()\n",
        "\n",
        "            if ((step + 1) % CFG['verbose_step'] == 0) or ((step + 1) == len(train_loader)):\n",
        "                description = f'epoch {epoch} loss: {running_loss:.4f}'\n",
        "\n",
        "                pbar.set_description(description)\n",
        "\n",
        "    if scheduler is not None and not schd_batch_update:\n",
        "        scheduler.step()\n",
        "\n",
        "def valid_one_epoch(epoch, model, loss_fn, val_loader, device, scheduler=None, schd_loss_update=False):\n",
        "    model.eval()\n",
        "\n",
        "    t = time.time()\n",
        "    loss_sum = 0\n",
        "    sample_num = 0\n",
        "    image_preds_all = []\n",
        "    image_targets_all = []\n",
        "\n",
        "    pbar = tqdm(enumerate(val_loader), total=len(val_loader))\n",
        "    for step, (imgs, image_labels) in pbar:\n",
        "        imgs = imgs.to(device).float()\n",
        "        image_labels = image_labels.to(device).long()\n",
        "\n",
        "        image_preds = model(imgs)\n",
        "        image_preds_all += [torch.argmax(image_preds, 1).detach().cpu().numpy()]\n",
        "        image_targets_all += [image_labels.detach().cpu().numpy()]\n",
        "\n",
        "        loss = loss_fn(image_preds, image_labels)\n",
        "\n",
        "        loss_sum += loss.item()*image_labels.shape[0]\n",
        "        sample_num += image_labels.shape[0]\n",
        "\n",
        "        if ((step + 1) % CFG['verbose_step'] == 0) or ((step + 1) == len(val_loader)):\n",
        "            description = f'epoch {epoch} loss: {loss_sum/sample_num:.4f}'\n",
        "            pbar.set_description(description)\n",
        "\n",
        "    image_preds_all = np.concatenate(image_preds_all)\n",
        "    image_targets_all = np.concatenate(image_targets_all)\n",
        "    print('validation multi-class accuracy = {:.4f}'.format((image_preds_all==image_targets_all).mean()))\n",
        "\n",
        "    if scheduler is not None:\n",
        "        if schd_loss_update:\n",
        "            scheduler.step(loss_sum/sample_num)\n",
        "        else:\n",
        "            scheduler.step()"
      ],
      "metadata": {
        "id": "qObxUhBuRtKZ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Main loop"
      ],
      "metadata": {
        "id": "Jo-AraGNWYRA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "     # for training only, need nightly build pytorch\n",
        "\n",
        "    seed_everything(CFG['seed'])\n",
        "\n",
        "    folds = StratifiedKFold(n_splits=CFG['fold_num'], shuffle=True, random_state=CFG['seed']).split(np.arange(train.shape[0]), train.label.values)\n",
        "\n",
        "    for fold, (trn_idx, val_idx) in enumerate(folds):\n",
        "        print('Training with {} started'.format(fold))\n",
        "        print(len(trn_idx), len(val_idx))\n",
        "\n",
        "        train_loader, val_loader = prepare_dataloader(train, trn_idx, val_idx)\n",
        "\n",
        "        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "        model = MyImgClassifier(CFG['model_arch'], train.label.nunique(), pretrained=True).to(device)\n",
        "        scaler = GradScaler()\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr=CFG['lr'], weight_decay=CFG['weight_decay'])\n",
        "        scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=CFG['T_0'], T_mult=1, eta_min=CFG['min_lr'], last_epoch=-1)\n",
        "\n",
        "        loss_tr = nn.CrossEntropyLoss().to(device)\n",
        "        loss_fn = nn.CrossEntropyLoss().to(device)\n",
        "\n",
        "        for epoch in range(CFG['epochs']):\n",
        "            train_one_epoch(epoch, model, loss_tr, optimizer, train_loader, device, scaler, scheduler=scheduler, schd_batch_update=False)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                valid_one_epoch(epoch, model, loss_fn, val_loader, device, scheduler=None, schd_loss_update=False)\n",
        "\n",
        "            torch.save(model.state_dict(), os.path.join(save_model_dir,'{}_fold_{}_{}'.format(CFG['model_arch'], fold, epoch)))\n",
        "\n",
        "        del model, optimizer, train_loader, val_loader, scaler, scheduler\n",
        "        torch.cuda.empty_cache()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dYtn32QkWViK",
        "outputId": "eb591cdf-86d3-455f-c904-a34ac6540eae"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training with 0 started\n",
            "674 169\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/albumentations/augmentations/dropout/cutout.py:49: FutureWarning: Cutout has been deprecated. Please use CoarseDropout\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "/usr/local/lib/python3.10/dist-packages/timm/models/_factory.py:114: UserWarning: Mapping deprecated model name tf_efficientnet_b4_ns to current tf_efficientnet_b4.ns_jft_in1k.\n",
            "  model = create_fn(\n",
            "epoch 0 loss: 1.3043: 100%|██████████| 43/43 [00:25<00:00,  1.72it/s]\n",
            "epoch 0 loss: 0.8242: 100%|██████████| 6/6 [00:04<00:00,  1.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "validation multi-class accuracy = 0.8166\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 1 loss: 0.7716: 100%|██████████| 43/43 [00:22<00:00,  1.91it/s]\n",
            "epoch 1 loss: 0.3531: 100%|██████████| 6/6 [00:04<00:00,  1.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "validation multi-class accuracy = 0.9112\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 2 loss: 0.5202: 100%|██████████| 43/43 [00:22<00:00,  1.92it/s]\n",
            "epoch 2 loss: 0.1238: 100%|██████████| 6/6 [00:04<00:00,  1.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "validation multi-class accuracy = 0.9822\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 3 loss: 0.3106: 100%|██████████| 43/43 [00:23<00:00,  1.85it/s]\n",
            "epoch 3 loss: 0.0867: 100%|██████████| 6/6 [00:04<00:00,  1.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "validation multi-class accuracy = 0.9882\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 4 loss: 0.1308: 100%|██████████| 43/43 [00:22<00:00,  1.93it/s]\n",
            "epoch 4 loss: 0.0648: 100%|██████████| 6/6 [00:04<00:00,  1.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "validation multi-class accuracy = 0.9941\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 5 loss: 0.1939: 100%|██████████| 43/43 [00:22<00:00,  1.94it/s]\n",
            "epoch 5 loss: 0.0603: 100%|██████████| 6/6 [00:04<00:00,  1.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "validation multi-class accuracy = 0.9941\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 6 loss: 0.0854: 100%|██████████| 43/43 [00:22<00:00,  1.93it/s]\n",
            "epoch 6 loss: 0.0563: 100%|██████████| 6/6 [00:05<00:00,  1.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "validation multi-class accuracy = 0.9941\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 7 loss: 0.1711: 100%|██████████| 43/43 [00:22<00:00,  1.93it/s]\n",
            "epoch 7 loss: 0.0651: 100%|██████████| 6/6 [00:04<00:00,  1.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "validation multi-class accuracy = 0.9941\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 8 loss: 0.1187: 100%|██████████| 43/43 [00:22<00:00,  1.91it/s]\n",
            "epoch 8 loss: 0.0618: 100%|██████████| 6/6 [00:05<00:00,  1.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "validation multi-class accuracy = 0.9941\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 9 loss: 0.1308: 100%|██████████| 43/43 [00:22<00:00,  1.93it/s]\n",
            "epoch 9 loss: 0.0510: 100%|██████████| 6/6 [00:05<00:00,  1.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "validation multi-class accuracy = 0.9941\n",
            "Training with 1 started\n",
            "674 169\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/albumentations/augmentations/dropout/cutout.py:49: FutureWarning: Cutout has been deprecated. Please use CoarseDropout\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "/usr/local/lib/python3.10/dist-packages/timm/models/_factory.py:114: UserWarning: Mapping deprecated model name tf_efficientnet_b4_ns to current tf_efficientnet_b4.ns_jft_in1k.\n",
            "  model = create_fn(\n",
            "epoch 0 loss: 1.2976: 100%|██████████| 43/43 [00:22<00:00,  1.91it/s]\n",
            "epoch 0 loss: 0.7236: 100%|██████████| 6/6 [00:05<00:00,  1.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "validation multi-class accuracy = 0.6923\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 1 loss: 0.6523: 100%|██████████| 43/43 [00:22<00:00,  1.92it/s]\n",
            "epoch 1 loss: 0.2853: 100%|██████████| 6/6 [00:05<00:00,  1.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "validation multi-class accuracy = 0.9349\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 2 loss: 0.3553: 100%|██████████| 43/43 [00:22<00:00,  1.91it/s]\n",
            "epoch 2 loss: 0.1107: 100%|██████████| 6/6 [00:04<00:00,  1.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "validation multi-class accuracy = 0.9704\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 3 loss: 0.2955: 100%|██████████| 43/43 [00:22<00:00,  1.91it/s]\n",
            "epoch 3 loss: 0.0932: 100%|██████████| 6/6 [00:04<00:00,  1.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "validation multi-class accuracy = 0.9822\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 4 loss: 0.2065: 100%|██████████| 43/43 [00:22<00:00,  1.93it/s]\n",
            "epoch 4 loss: 0.1015: 100%|██████████| 6/6 [00:04<00:00,  1.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "validation multi-class accuracy = 0.9763\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 5 loss: 0.4032: 100%|██████████| 43/43 [00:22<00:00,  1.94it/s]\n",
            "epoch 5 loss: 0.0979: 100%|██████████| 6/6 [00:04<00:00,  1.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "validation multi-class accuracy = 0.9704\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 6 loss: 0.0764: 100%|██████████| 43/43 [00:22<00:00,  1.90it/s]\n",
            "epoch 6 loss: 0.0719: 100%|██████████| 6/6 [00:04<00:00,  1.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "validation multi-class accuracy = 0.9882\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 7 loss: 0.1559: 100%|██████████| 43/43 [00:22<00:00,  1.89it/s]\n",
            "epoch 7 loss: 0.0754: 100%|██████████| 6/6 [00:04<00:00,  1.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "validation multi-class accuracy = 0.9882\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 8 loss: 0.1056: 100%|██████████| 43/43 [00:22<00:00,  1.93it/s]\n",
            "epoch 8 loss: 0.0847: 100%|██████████| 6/6 [00:04<00:00,  1.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "validation multi-class accuracy = 0.9882\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 9 loss: 0.2663: 100%|██████████| 43/43 [00:22<00:00,  1.93it/s]\n",
            "epoch 9 loss: 0.0772: 100%|██████████| 6/6 [00:04<00:00,  1.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "validation multi-class accuracy = 0.9882\n",
            "Training with 2 started\n",
            "674 169\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/albumentations/augmentations/dropout/cutout.py:49: FutureWarning: Cutout has been deprecated. Please use CoarseDropout\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "/usr/local/lib/python3.10/dist-packages/timm/models/_factory.py:114: UserWarning: Mapping deprecated model name tf_efficientnet_b4_ns to current tf_efficientnet_b4.ns_jft_in1k.\n",
            "  model = create_fn(\n",
            "epoch 0 loss: 1.3044: 100%|██████████| 43/43 [00:22<00:00,  1.89it/s]\n",
            "epoch 0 loss: 0.7641: 100%|██████████| 6/6 [00:04<00:00,  1.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "validation multi-class accuracy = 0.8698\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 1 loss: 0.7866: 100%|██████████| 43/43 [00:22<00:00,  1.92it/s]\n",
            "epoch 1 loss: 0.3190: 100%|██████████| 6/6 [00:04<00:00,  1.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "validation multi-class accuracy = 0.9231\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 2 loss: 0.3231: 100%|██████████| 43/43 [00:22<00:00,  1.94it/s]\n",
            "epoch 2 loss: 0.1505: 100%|██████████| 6/6 [00:04<00:00,  1.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "validation multi-class accuracy = 0.9586\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 3 loss: 0.3337: 100%|██████████| 43/43 [00:22<00:00,  1.91it/s]\n",
            "epoch 3 loss: 0.1070: 100%|██████████| 6/6 [00:04<00:00,  1.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "validation multi-class accuracy = 0.9822\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 4 loss: 0.1324: 100%|██████████| 43/43 [00:23<00:00,  1.86it/s]\n",
            "epoch 4 loss: 0.0880: 100%|██████████| 6/6 [00:04<00:00,  1.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "validation multi-class accuracy = 0.9822\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 5 loss: 0.1246: 100%|██████████| 43/43 [00:23<00:00,  1.85it/s]\n",
            "epoch 5 loss: 0.0827: 100%|██████████| 6/6 [00:04<00:00,  1.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "validation multi-class accuracy = 0.9822\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 6 loss: 0.2769: 100%|██████████| 43/43 [00:23<00:00,  1.83it/s]\n",
            "epoch 6 loss: 0.0662: 100%|██████████| 6/6 [00:04<00:00,  1.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "validation multi-class accuracy = 0.9882\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 7 loss: 0.2197: 100%|██████████| 43/43 [00:23<00:00,  1.82it/s]\n",
            "epoch 7 loss: 0.0656: 100%|██████████| 6/6 [00:04<00:00,  1.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "validation multi-class accuracy = 0.9882\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 8 loss: 0.0866: 100%|██████████| 43/43 [00:23<00:00,  1.82it/s]\n",
            "epoch 8 loss: 0.0594: 100%|██████████| 6/6 [00:04<00:00,  1.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "validation multi-class accuracy = 0.9941\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 9 loss: 0.1720: 100%|██████████| 43/43 [00:23<00:00,  1.81it/s]\n",
            "epoch 9 loss: 0.0590: 100%|██████████| 6/6 [00:04<00:00,  1.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "validation multi-class accuracy = 0.9882\n",
            "Training with 3 started\n",
            "675 168\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/albumentations/augmentations/dropout/cutout.py:49: FutureWarning: Cutout has been deprecated. Please use CoarseDropout\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "/usr/local/lib/python3.10/dist-packages/timm/models/_factory.py:114: UserWarning: Mapping deprecated model name tf_efficientnet_b4_ns to current tf_efficientnet_b4.ns_jft_in1k.\n",
            "  model = create_fn(\n",
            "epoch 0 loss: 1.3137: 100%|██████████| 43/43 [00:27<00:00,  1.54it/s]\n",
            "epoch 0 loss: 0.8566: 100%|██████████| 6/6 [00:05<00:00,  1.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "validation multi-class accuracy = 0.8571\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 1 loss: 0.8204: 100%|██████████| 43/43 [00:22<00:00,  1.91it/s]\n",
            "epoch 1 loss: 0.3259: 100%|██████████| 6/6 [00:04<00:00,  1.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "validation multi-class accuracy = 0.9167\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 2 loss: 0.4385: 100%|██████████| 43/43 [00:22<00:00,  1.91it/s]\n",
            "epoch 2 loss: 0.1217: 100%|██████████| 6/6 [00:04<00:00,  1.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "validation multi-class accuracy = 0.9702\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 3 loss: 0.2122: 100%|██████████| 43/43 [00:22<00:00,  1.92it/s]\n",
            "epoch 3 loss: 0.0850: 100%|██████████| 6/6 [00:04<00:00,  1.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "validation multi-class accuracy = 0.9762\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 4 loss: 0.2144: 100%|██████████| 43/43 [00:22<00:00,  1.91it/s]\n",
            "epoch 4 loss: 0.0576: 100%|██████████| 6/6 [00:04<00:00,  1.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "validation multi-class accuracy = 0.9821\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 5 loss: 0.2905: 100%|██████████| 43/43 [00:22<00:00,  1.90it/s]\n",
            "epoch 5 loss: 0.0512: 100%|██████████| 6/6 [00:04<00:00,  1.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "validation multi-class accuracy = 0.9881\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 6 loss: 0.2509: 100%|██████████| 43/43 [00:22<00:00,  1.92it/s]\n",
            "epoch 6 loss: 0.0410: 100%|██████████| 6/6 [00:04<00:00,  1.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "validation multi-class accuracy = 0.9940\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 7 loss: 0.1526: 100%|██████████| 43/43 [00:22<00:00,  1.93it/s]\n",
            "epoch 7 loss: 0.0508: 100%|██████████| 6/6 [00:04<00:00,  1.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "validation multi-class accuracy = 0.9881\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 8 loss: 0.1381: 100%|██████████| 43/43 [00:22<00:00,  1.89it/s]\n",
            "epoch 8 loss: 0.0454: 100%|██████████| 6/6 [00:04<00:00,  1.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "validation multi-class accuracy = 0.9821\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 9 loss: 0.2139: 100%|██████████| 43/43 [00:23<00:00,  1.87it/s]\n",
            "epoch 9 loss: 0.0388: 100%|██████████| 6/6 [00:04<00:00,  1.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "validation multi-class accuracy = 0.9940\n",
            "Training with 4 started\n",
            "675 168\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/albumentations/augmentations/dropout/cutout.py:49: FutureWarning: Cutout has been deprecated. Please use CoarseDropout\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "/usr/local/lib/python3.10/dist-packages/timm/models/_factory.py:114: UserWarning: Mapping deprecated model name tf_efficientnet_b4_ns to current tf_efficientnet_b4.ns_jft_in1k.\n",
            "  model = create_fn(\n",
            "epoch 0 loss: 1.3027: 100%|██████████| 43/43 [00:22<00:00,  1.91it/s]\n",
            "epoch 0 loss: 0.7538: 100%|██████████| 6/6 [00:04<00:00,  1.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "validation multi-class accuracy = 0.8452\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 1 loss: 0.8900: 100%|██████████| 43/43 [00:22<00:00,  1.89it/s]\n",
            "epoch 1 loss: 0.2466: 100%|██████████| 6/6 [00:04<00:00,  1.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "validation multi-class accuracy = 0.9524\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 2 loss: 0.4377: 100%|██████████| 43/43 [00:22<00:00,  1.89it/s]\n",
            "epoch 2 loss: 0.1083: 100%|██████████| 6/6 [00:04<00:00,  1.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "validation multi-class accuracy = 0.9762\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 3 loss: 0.1684: 100%|██████████| 43/43 [00:23<00:00,  1.84it/s]\n",
            "epoch 3 loss: 0.0693: 100%|██████████| 6/6 [00:04<00:00,  1.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "validation multi-class accuracy = 0.9881\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 4 loss: 0.1366: 100%|██████████| 43/43 [00:22<00:00,  1.90it/s]\n",
            "epoch 4 loss: 0.0672: 100%|██████████| 6/6 [00:04<00:00,  1.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "validation multi-class accuracy = 0.9881\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 5 loss: 0.1316: 100%|██████████| 43/43 [00:22<00:00,  1.92it/s]\n",
            "epoch 5 loss: 0.0559: 100%|██████████| 6/6 [00:04<00:00,  1.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "validation multi-class accuracy = 0.9881\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 6 loss: 0.3350: 100%|██████████| 43/43 [00:22<00:00,  1.90it/s]\n",
            "epoch 6 loss: 0.0443: 100%|██████████| 6/6 [00:04<00:00,  1.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "validation multi-class accuracy = 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 7 loss: 0.0853: 100%|██████████| 43/43 [00:22<00:00,  1.90it/s]\n",
            "epoch 7 loss: 0.0452: 100%|██████████| 6/6 [00:04<00:00,  1.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "validation multi-class accuracy = 0.9940\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 8 loss: 0.1698: 100%|██████████| 43/43 [00:22<00:00,  1.92it/s]\n",
            "epoch 8 loss: 0.0384: 100%|██████████| 6/6 [00:04<00:00,  1.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "validation multi-class accuracy = 0.9881\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 9 loss: 0.1184: 100%|██████████| 43/43 [00:22<00:00,  1.89it/s]\n",
            "epoch 9 loss: 0.0357: 100%|██████████| 6/6 [00:04<00:00,  1.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "validation multi-class accuracy = 1.0000\n"
          ]
        }
      ]
    }
  ]
}